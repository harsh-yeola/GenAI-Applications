{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892e31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "# from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. CHUNK RISK DEFINITIONS AND CREATE VECTOR STORE\n",
    "# ============================================================\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "risk_chunks = text_splitter.split_text(risk_definitions_text)\n",
    "\n",
    "# use Google GenAI embeddings (class is imported at top of the notebook)\n",
    "embeddings = GoogleGenerativeAIEmbeddings()\n",
    "\n",
    "# Chroma expects the kwarg name `embeddings`\n",
    "vectorstore = Chroma.from_texts(risk_chunks, embeddings=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "``````python\n",
    "# ============================================================\n",
    "# 3. BUILD RAG LLM CHAIN\n",
    "# ============================================================\n",
    "\n",
    "# use Google GenAI chat model (class is imported at top of the notebook)\n",
    "llm = ChatGoogleGenerativeAI(model=\"chat-bison-001\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a senior banking risk officer.\n",
    "Use the retrieved bank-specific risk definitions below to classify the event.\n",
    "\n",
    "=== Risk Definitions ===\n",
    "{context}\n",
    "\n",
    "=== Event Description ===\n",
    "{issue_description}\n",
    "\n",
    "TASKS:\n",
    "1. Produce a 5–8 word \"gist\" capturing the core issue.\n",
    "2. Provide a short \"rationale\" (1 sentence) explaining *why* the chosen risk applies.\n",
    "3. Select ONLY the single most appropriate \"risk_type\" using the risk definitions.\n",
    "\n",
    "Return ONLY JSON in this format:\n",
    "{{\n",
    "  \"gist\": \"...\",\n",
    "  \"rationale\": \"...\",\n",
    "  \"risk_type\": \"...\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        context=retriever,\n",
    "        issue_description=RunnablePassthrough()\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "``````python\n",
    "# ============================================================\n",
    "# 4. PROCESS THE ENTIRE DATASET\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "\n",
    "gists = []\n",
    "rationales = []\n",
    "risk_types = []\n",
    "\n",
    "for desc in df[\"issue_description\"].tolist():\n",
    "    out = rag_chain.invoke({\"issue_description\": desc})\n",
    "\n",
    "    # normalize to a string containing the model response\n",
    "    if hasattr(out, \"content\"):\n",
    "        raw = out.content\n",
    "    elif isinstance(out, (list, tuple)) and len(out) > 0:\n",
    "        first = out[0]\n",
    "        raw = getattr(first, \"content\", str(first))\n",
    "    else:\n",
    "        raw = str(out)\n",
    "\n",
    "    parsed = None\n",
    "    # try eval (legacy) then JSON\n",
    "    try:\n",
    "        parsed = eval(raw)\n",
    "    except Exception:\n",
    "        try:\n",
    "            parsed = json.loads(raw)\n",
    "        except Exception:\n",
    "            parsed = None\n",
    "\n",
    "    if isinstance(parsed, dict):\n",
    "        gists.append(parsed.get(\"gist\", \"\"))\n",
    "        rationales.append(parsed.get(\"rationale\", \"\"))\n",
    "        risk_types.append(parsed.get(\"risk_type\", \"\"))\n",
    "    else:\n",
    "        # fallback\n",
    "        gists.append(\"Unable to extract gist\")\n",
    "        rationales.append(\"Unable to infer rationale\")\n",
    "        risk_types.append(\"Unknown\")\n",
    "\n",
    "df[\"gist\"] = gists\n",
    "df[\"rationale\"] = rationales\n",
    "df[\"risk_type\"] = risk_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. READ USER-UPLOADED FILES\n",
    "# ============================================================\n",
    "\n",
    "csv_path = \"./banking_risk_analysis/banking_issues_all.csv\"\n",
    "risk_def_path = \"./Non Financial Risk.txt\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "with open(risk_def_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    risk_definitions_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. CHUNK RISK DEFINITIONS AND CREATE VECTOR STORE\n",
    "# ============================================================\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "risk_chunks = text_splitter.split_text(risk_definitions_text)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "vectorstore = Chroma.from_texts(risk_chunks, embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65288fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. BUILD RAG LLM CHAIN\n",
    "# ============================================================\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a senior banking risk officer.\n",
    "Use the retrieved bank-specific risk definitions below to classify the event.\n",
    "\n",
    "=== Risk Definitions ===\n",
    "{context}\n",
    "\n",
    "=== Event Description ===\n",
    "{issue_description}\n",
    "\n",
    "TASKS:\n",
    "1. Produce a 5–8 word \"gist\" capturing the core issue.\n",
    "2. Provide a short \"rationale\" (1 sentence) explaining *why* the chosen risk applies.\n",
    "3. Select ONLY the single most appropriate \"risk_type\" using the risk definitions.\n",
    "\n",
    "Return ONLY JSON in this format:\n",
    "{{\n",
    "  \"gist\": \"...\",\n",
    "  \"rationale\": \"...\",\n",
    "  \"risk_type\": \"...\"\n",
    "}}\n",
    "\"\"\")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        context=retriever,\n",
    "        issue_description=RunnablePassthrough()\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. PROCESS THE ENTIRE DATASET\n",
    "# ============================================================\n",
    "\n",
    "gists = []\n",
    "rationales = []\n",
    "risk_types = []\n",
    "\n",
    "for desc in df[\"issue_description\"].tolist():\n",
    "    out = rag_chain.invoke({\"issue_description\": desc})\n",
    "    try:\n",
    "        parsed = eval(out.content)\n",
    "        gists.append(parsed.get(\"gist\", \"\"))\n",
    "        rationales.append(parsed.get(\"rationale\", \"\"))\n",
    "        risk_types.append(parsed.get(\"risk_type\", \"\"))\n",
    "    except:\n",
    "        # fallback\n",
    "        gists.append(\"Unable to extract gist\")\n",
    "        rationales.append(\"Unable to infer rationale\")\n",
    "        risk_types.append(\"Unknown\")\n",
    "\n",
    "df[\"gist\"] = gists\n",
    "df[\"rationale\"] = rationales\n",
    "df[\"risk_type\"] = risk_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. SAVE FINAL DATAFRAME\n",
    "# ============================================================\n",
    "\n",
    "output_path = \"/mnt/data/risk_classified_output.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
