{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f59fa7",
   "metadata": {
    "papermill": {
     "duration": 0.006,
     "end_time": "2025-01-19T09:31:35.626013",
     "exception": false,
     "start_time": "2025-01-19T09:31:35.620013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LangChain Document Indexing Comprehensive Guide\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "The **LangChain Indexing API** is a powerful tool designed to streamline the process of loading and synchronizing documents into a vector store. It addresses common challenges such as avoiding duplicate content, re-writing unchanged content, and re-computing embeddings unnecessarily. By leveraging a **Record Manager**, the API tracks document writes and ensures that only new or updated content is processed, saving both time and computational resources. This makes it an ideal solution for maintaining up-to-date and efficient vector stores, even when documents undergo multiple transformations (e.g., text chunking).\n",
    "\n",
    "The API supports multiple **deletion modes**, allowing users to choose how existing documents in the vector store are handled during indexing. Whether you need to avoid automatic cleanup, continuously clean up old versions, or perform a full refresh of the vector store, the LangChain Indexing API provides the flexibility to meet your needs. This guide explores the key features of the API, its deletion modes, and how to use it effectively with compatible vector stores.\n",
    "\n",
    "### **Comparison of Deletion Modes**\n",
    "\n",
    "| **Feature**                        | **None**                  | **Incremental**           | **Full**                   | **Scoped_Full**             |\n",
    "|------------------------------------|---------------------------|---------------------------|----------------------------|-----------------------------|\n",
    "| **De-Duplicates Content**          | ✅                        | ✅                        | ✅                         | ✅                          |\n",
    "| **Parallelizable**                 | ✅                        | ✅                        | ❌                         | ✅                          |\n",
    "| **Cleans Up Deleted Source Docs**  | ❌                        | ❌                        | ✅                         | ❌                          |\n",
    "| **Cleans Up Mutations of Source/Derived Docs** | ❌                        | ✅                        | ✅                         | ✅                          |\n",
    "| **Clean Up Timing**                | -                         | Continuously              | At end of indexing         | At end of indexing          |\n",
    "| **Best Use Case**                  | Manual control over deletions; no automatic cleanup. | Frequent updates with minimal overlap between old and new versions. | Complete dataset refresh or handling deletions of source documents. | Partial dataset refresh with parallel processing. |\n",
    "\n",
    "### **How to Use This Table**\n",
    "- **De-Duplicates Content**: Check if the mode avoids re-indexing duplicate content.\n",
    "- **Parallelizable**: Determine if the mode supports parallel processing for faster indexing.\n",
    "- **Cleans Up Deleted Source Docs**: See if the mode automatically removes documents that are no longer in the input.\n",
    "- **Cleans Up Mutations**: Check if the mode handles updates to source or derived documents.\n",
    "- **Clean Up Timing**: Understand when the cleanup occurs (continuously or at the end of indexing).\n",
    "- **Best Use Case**: Match the mode to your specific workflow requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f34ff",
   "metadata": {
    "papermill": {
     "duration": 0.005184,
     "end_time": "2025-01-19T09:31:35.636893",
     "exception": false,
     "start_time": "2025-01-19T09:31:35.631709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Preparation\n",
    "\n",
    "### Installing Required Libraries\n",
    "This section installs the necessary Python libraries for working with LangChain, OpenAI embeddings, and Chroma vector store. These libraries include:\n",
    "- `langchain-openai`: Provides integration with OpenAI's embedding models.\n",
    "- `langchain_community`: Contains community-contributed modules and tools for LangChain.\n",
    "- `langchain_experimental`: Includes experimental features and utilities for LangChain.\n",
    "- `langchain-chroma`: Enables integration with the Chroma vector database.\n",
    "- `chromadb`: The core library for the Chroma vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36d181f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-19T09:31:35.649125Z",
     "iopub.status.busy": "2025-01-19T09:31:35.648612Z",
     "iopub.status.idle": "2025-01-19T09:32:44.057841Z",
     "shell.execute_reply": "2025-01-19T09:32:44.056344Z"
    },
    "papermill": {
     "duration": 68.41795,
     "end_time": "2025-01-19T09:32:44.060139",
     "exception": false,
     "start_time": "2025-01-19T09:31:35.642189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.9/411.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.6/455.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\r\n",
      "transformers 4.47.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "langchain-chroma 0.2.0 requires chromadb!=0.5.10,!=0.5.11,!=0.5.12,!=0.5.4,!=0.5.5,!=0.5.7,!=0.5.9,<0.6.0,>=0.4.0, but you have chromadb 0.6.3 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-openai\n",
    "!pip install -qU langchain_community\n",
    "!pip install -qU langchain_experimental\n",
    "!pip install -qU langchain-chroma>=0.1.2\n",
    "!pip install -qU chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b051a91",
   "metadata": {
    "papermill": {
     "duration": 0.006442,
     "end_time": "2025-01-19T09:32:44.073105",
     "exception": false,
     "start_time": "2025-01-19T09:32:44.066663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing OpenAI Embeddings\n",
    "This section demonstrates how to securely fetch an OpenAI API key using Kaggle's `UserSecretsClient` and initialize the OpenAI embedding model. The `OpenAIEmbeddings` class is used to create an embedding model instance, which will be used to convert text into numerical embeddings.\n",
    "\n",
    "Key steps:\n",
    "1. **Fetch API Key**: The OpenAI API key is securely retrieved using Kaggle's `UserSecretsClient`.\n",
    "2. **Initialize Embeddings**: The `OpenAIEmbeddings` class is initialized with the `text-embedding-3-small` model and the fetched API key.\n",
    "\n",
    "This setup ensures that the embedding model is ready for use in downstream tasks, such as caching embeddings or creating vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00051c2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:44.087678Z",
     "iopub.status.busy": "2025-01-19T09:32:44.087239Z",
     "iopub.status.idle": "2025-01-19T09:32:46.983681Z",
     "shell.execute_reply": "2025-01-19T09:32:46.982624Z"
    },
    "papermill": {
     "duration": 2.906147,
     "end_time": "2025-01-19T09:32:46.985651",
     "exception": false,
     "start_time": "2025-01-19T09:32:44.079504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Fetch API key securely\n",
    "user_secrets = UserSecretsClient()\n",
    "my_api_key = user_secrets.get_secret(\"api-key-openai\")\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embed = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=my_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f06f47",
   "metadata": {
    "papermill": {
     "duration": 0.006022,
     "end_time": "2025-01-19T09:32:46.998237",
     "exception": false,
     "start_time": "2025-01-19T09:32:46.992215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 1. **None Deletion Mode**\n",
    "This mode **does not perform automatic cleanup** of old content. It ensures that duplicate content is not re-indexed, but it leaves existing documents untouched unless explicitly removed.\n",
    "\n",
    "### **Key Features of None Deletion Mode**\n",
    "1. **No Automatic Cleanup**: Existing documents in the vector store are **not deleted**, even if they are no longer part of the input.\n",
    "2. **De-Duplication**: Ensures that duplicate content is **not re-indexed**, saving time and resources.\n",
    "3. **Manual Control**: You retain full control over document deletions, making it suitable for scenarios where you want to manage deletions explicitly.\n",
    "\n",
    "### **When to Use None Deletion Mode**\n",
    "- When you want to **avoid automatic deletions** of existing documents.\n",
    "- When you need to **manually manage** the lifecycle of documents in the vector store.\n",
    "- When you want to ensure **no unintended data loss** during indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf350e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:47.012202Z",
     "iopub.status.busy": "2025-01-19T09:32:47.011723Z",
     "iopub.status.idle": "2025-01-19T09:32:49.674521Z",
     "shell.execute_reply": "2025-01-19T09:32:49.673704Z"
    },
    "papermill": {
     "duration": 2.671963,
     "end_time": "2025-01-19T09:32:49.676393",
     "exception": false,
     "start_time": "2025-01-19T09:32:47.004430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize Chroma Vectorstore with OpenAI embeddings\n",
    "collection_name = \"test_index\"\n",
    "vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)\n",
    "\n",
    "# Initialize a record manager to track document writes\n",
    "namespace = f\"chroma/{collection_name}\"\n",
    "record_manager = SQLRecordManager(namespace, db_url=\"sqlite:///record_manager_cache.sql\")\n",
    "record_manager.create_schema()\n",
    "\n",
    "# Define test documents\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "# Helper function to clear content (used for setup)\n",
    "def _clear():\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "# Clear the vector store and record manager (setup for a clean state)\n",
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95178f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:49.690250Z",
     "iopub.status.busy": "2025-01-19T09:32:49.689719Z",
     "iopub.status.idle": "2025-01-19T09:32:52.849942Z",
     "shell.execute_reply": "2025-01-19T09:32:52.848868Z"
    },
    "papermill": {
     "duration": 3.169,
     "end_time": "2025-01-19T09:32:52.851662",
     "exception": false,
     "start_time": "2025-01-19T09:32:49.682662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 1, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index documents with None deletion mode\n",
    "# Feature: No automatic cleanup of old content\n",
    "# Explanation: Only one unique document is added, even though `doc1` is provided multiple times.\n",
    "index([doc1, doc1, doc1, doc1, doc1], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc74c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:52.865658Z",
     "iopub.status.busy": "2025-01-19T09:32:52.865273Z",
     "iopub.status.idle": "2025-01-19T09:32:53.437788Z",
     "shell.execute_reply": "2025-01-19T09:32:53.436414Z"
    },
    "papermill": {
     "duration": 0.581635,
     "end_time": "2025-01-19T09:32:53.439692",
     "exception": false,
     "start_time": "2025-01-19T09:32:52.858057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 1, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index new documents\n",
    "# Explanation: `doc1` is skipped (already indexed), and `doc2` is added.\n",
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efa442af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:53.457748Z",
     "iopub.status.busy": "2025-01-19T09:32:53.457338Z",
     "iopub.status.idle": "2025-01-19T09:32:53.501461Z",
     "shell.execute_reply": "2025-01-19T09:32:53.500278Z"
    },
    "papermill": {
     "duration": 0.053503,
     "end_time": "2025-01-19T09:32:53.503288",
     "exception": false,
     "start_time": "2025-01-19T09:32:53.449785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second run skips all content\n",
    "# Explanation: Both documents are already indexed, so nothing is added or updated.\n",
    "index([doc1, doc2], record_manager, vectorstore, cleanup=None, source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d52e1",
   "metadata": {
    "papermill": {
     "duration": 0.006311,
     "end_time": "2025-01-19T09:32:53.516380",
     "exception": false,
     "start_time": "2025-01-19T09:32:53.510069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 2. **Incremental Deletion Mode**\n",
    "This mode **continuously cleans up old versions of content** as new versions are indexed. It ensures that the vector store stays up-to-date by removing outdated documents while minimizing the time window during which both old and new versions coexist.\n",
    "\n",
    "### **Key Features of Incremental Deletion Mode**\n",
    "1. **Continuous Cleanup**: Old versions of documents are **automatically deleted** as new versions are indexed, ensuring the vector store reflects the latest content.\n",
    "2. **Efficient Updates**: Only **changed or new documents** are processed, avoiding unnecessary re-indexing of unchanged content.\n",
    "3. **Minimized Overlap**: The time window during which both old and new versions coexist is minimized, reducing the risk of returning outdated results.\n",
    "\n",
    "### **When to Use Incremental Deletion Mode**\n",
    "- When you want to **keep the vector store up-to-date** with the latest versions of your documents.\n",
    "- When you need to **efficiently handle frequent updates** to your source documents.\n",
    "- When you want to **avoid a full rebuild** of the vector store while ensuring consistency.\n",
    "\n",
    "### **Example Workflow**\n",
    "1. **Initial Indexing**: Add documents to the vector store.\n",
    "2. **Subsequent Updates**: Update or add new documents. Outdated versions are automatically cleaned up.\n",
    "3. **No Changes**: If no changes are detected, the process is skipped, saving time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0213709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:53.530785Z",
     "iopub.status.busy": "2025-01-19T09:32:53.530368Z",
     "iopub.status.idle": "2025-01-19T09:32:53.565980Z",
     "shell.execute_reply": "2025-01-19T09:32:53.565144Z"
    },
    "papermill": {
     "duration": 0.045008,
     "end_time": "2025-01-19T09:32:53.567899",
     "exception": false,
     "start_time": "2025-01-19T09:32:53.522891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize Chroma Vectorstore with OpenAI embeddings\n",
    "collection_name = \"test_index\"\n",
    "vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)\n",
    "\n",
    "# Initialize a record manager to track document writes\n",
    "namespace = f\"chroma/{collection_name}\"\n",
    "record_manager = SQLRecordManager(namespace, db_url=\"sqlite:///record_manager_cache.sql\")\n",
    "record_manager.create_schema()\n",
    "\n",
    "# Define test documents\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "# Helper function to clear content (used for setup)\n",
    "def _clear():\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "# Clear the vector store and record manager (setup for a clean state)\n",
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1d2bed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:53.582632Z",
     "iopub.status.busy": "2025-01-19T09:32:53.582145Z",
     "iopub.status.idle": "2025-01-19T09:32:54.215383Z",
     "shell.execute_reply": "2025-01-19T09:32:54.214209Z"
    },
    "papermill": {
     "duration": 0.642749,
     "end_time": "2025-01-19T09:32:54.217296",
     "exception": false,
     "start_time": "2025-01-19T09:32:53.574547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index documents with Incremental deletion mode\n",
    "# Feature: Automatically cleans up old versions of content\n",
    "# Explanation: Both documents are added to the vector store.\n",
    "index([doc1, doc2], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d405c8d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:54.232503Z",
     "iopub.status.busy": "2025-01-19T09:32:54.232133Z",
     "iopub.status.idle": "2025-01-19T09:32:54.265974Z",
     "shell.execute_reply": "2025-01-19T09:32:54.264848Z"
    },
    "papermill": {
     "duration": 0.043247,
     "end_time": "2025-01-19T09:32:54.267808",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.224561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second run skips both documents (no changes)\n",
    "# Explanation: No changes are detected, so both documents are skipped.\n",
    "index([doc1, doc2], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d92e8bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:54.283212Z",
     "iopub.status.busy": "2025-01-19T09:32:54.282879Z",
     "iopub.status.idle": "2025-01-19T09:32:54.290009Z",
     "shell.execute_reply": "2025-01-19T09:32:54.288779Z"
    },
    "papermill": {
     "duration": 0.016951,
     "end_time": "2025-01-19T09:32:54.291790",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.274839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No changes if no documents are provided\n",
    "# Explanation: No documents are provided, so nothing is added or deleted.\n",
    "index([], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a19a41a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:54.306831Z",
     "iopub.status.busy": "2025-01-19T09:32:54.306428Z",
     "iopub.status.idle": "2025-01-19T09:32:54.617839Z",
     "shell.execute_reply": "2025-01-19T09:32:54.616709Z"
    },
    "papermill": {
     "duration": 0.320883,
     "end_time": "2025-01-19T09:32:54.619610",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.298727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 1, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mutate a document and index the new version\n",
    "# Explanation: The new version of `doc2` is added, and the old version is deleted.\n",
    "changed_doc_2 = Document(page_content=\"puppy\", metadata={\"source\": \"doggy.txt\"})\n",
    "index([changed_doc_2], record_manager, vectorstore, cleanup=\"incremental\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3adbe16",
   "metadata": {
    "papermill": {
     "duration": 0.006634,
     "end_time": "2025-01-19T09:32:54.633900",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.627266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 3. **Full Deletion Mode**\n",
    "This mode ensures that **only the documents provided in the current batch** are retained in the vector store. Any existing documents not included in the batch are **automatically deleted**. This is particularly useful for handling **deletions of source documents** or performing **complete dataset refreshes**.\n",
    "\n",
    "### **Key Features of Full Deletion Mode**\n",
    "1. **Complete Control**: Ensures that the vector store contains **only the documents explicitly provided** in the current batch.\n",
    "2. **Handles Deletions**: Automatically deletes documents that are no longer part of the input, making it ideal for **removing outdated or deleted source documents**.\n",
    "3. **Dataset Refresh**: Suitable for scenarios where you need to perform a **complete refresh** of the vector store with a new set of documents.\n",
    "\n",
    "### **When to Use Full Deletion Mode**\n",
    "- When you want to **ensure the vector store matches exactly** the documents you provide in the current batch.\n",
    "- When you need to **handle deletions of source documents** (e.g., files or records that no longer exist).\n",
    "- When performing a **full dataset refresh** or replacing the entire content of the vector store.\n",
    "\n",
    "### **Example Workflow**\n",
    "1. **Initial Indexing**: Add a set of documents to the vector store.\n",
    "2. **Subsequent Updates**: Provide a new batch of documents. Any documents not included in the batch are **automatically deleted**.\n",
    "3. **Handling Deletions**: If a source document is removed from the input, it is also removed from the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe37a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:54.649483Z",
     "iopub.status.busy": "2025-01-19T09:32:54.649150Z",
     "iopub.status.idle": "2025-01-19T09:32:54.686102Z",
     "shell.execute_reply": "2025-01-19T09:32:54.685174Z"
    },
    "papermill": {
     "duration": 0.04743,
     "end_time": "2025-01-19T09:32:54.688185",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.640755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize Chroma Vectorstore with OpenAI embeddings\n",
    "collection_name = \"test_index\"\n",
    "vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)\n",
    "\n",
    "# Initialize a record manager to track document writes\n",
    "namespace = f\"chroma/{collection_name}\"\n",
    "record_manager = SQLRecordManager(namespace, db_url=\"sqlite:///record_manager_cache.sql\")\n",
    "record_manager.create_schema()\n",
    "\n",
    "# Define test documents\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "# Helper function to clear content (used for setup)\n",
    "def _clear():\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "# Clear the vector store and record manager (setup for a clean state)\n",
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1352c97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:54.703511Z",
     "iopub.status.busy": "2025-01-19T09:32:54.703146Z",
     "iopub.status.idle": "2025-01-19T09:32:55.340410Z",
     "shell.execute_reply": "2025-01-19T09:32:55.339268Z"
    },
    "papermill": {
     "duration": 0.646714,
     "end_time": "2025-01-19T09:32:55.342098",
     "exception": false,
     "start_time": "2025-01-19T09:32:54.695384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index documents with Full deletion mode\n",
    "# Feature: Only the provided documents are retained; others are deleted\n",
    "# Explanation: Both documents are added to the vector store.\n",
    "all_docs = [doc1, doc2]\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2443c39c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:55.357397Z",
     "iopub.status.busy": "2025-01-19T09:32:55.357075Z",
     "iopub.status.idle": "2025-01-19T09:32:55.409840Z",
     "shell.execute_reply": "2025-01-19T09:32:55.408443Z"
    },
    "papermill": {
     "duration": 0.062696,
     "end_time": "2025-01-19T09:32:55.411809",
     "exception": false,
     "start_time": "2025-01-19T09:32:55.349113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 1, 'num_deleted': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate deletion of the first document (e.g., \"kitty.txt\" is no longer needed)\n",
    "del all_docs[0]  # Remove `doc1` from the batch\n",
    "# Explanation: `doc1` is deleted from the vector store because it is no longer in the batch.\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd3326a",
   "metadata": {
    "papermill": {
     "duration": 0.006687,
     "end_time": "2025-01-19T09:32:55.426087",
     "exception": false,
     "start_time": "2025-01-19T09:32:55.419400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 4. **Scoped_Full Deletion Mode**\n",
    "\n",
    "### **Key Features of Scoped_Full Deletion Mode**\n",
    "1. **Partial Dataset Refresh**: Only the documents within the specified scope (e.g., `kitty.txt` and `doggy.txt`) are updated and cleaned up.\n",
    "2. **Parallel Processing**: Supports parallel execution, making it efficient for large datasets.\n",
    "3. **Cleanup at End of Indexing**: Old versions of the specified documents are deleted after the new versions are indexed.\n",
    "4. **No Cleanup of Unrelated Documents**: Documents outside the scope (e.g., `birdie.txt`) remain untouched.\n",
    "\n",
    "### **When to Use Scoped_Full Deletion Mode**\n",
    "- When you need to **update a subset of documents** in the vector store without affecting the rest.\n",
    "- When you want to **leverage parallel processing** for faster indexing.\n",
    "- When you need to **clean up old versions** of specific documents after updating them.\n",
    "\n",
    "### **Workflow Summary**\n",
    "1. **Initial Setup**: Populate the vector store with an initial set of documents using **Full Deletion Mode**.\n",
    "2. **Partial Update**: Use **Scoped_Full Deletion Mode** to update and clean up only the specified documents.\n",
    "3. **Verification**: Check the vector store to ensure the updates were applied correctly and unrelated documents remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ee2bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:55.441122Z",
     "iopub.status.busy": "2025-01-19T09:32:55.440790Z",
     "iopub.status.idle": "2025-01-19T09:32:55.479516Z",
     "shell.execute_reply": "2025-01-19T09:32:55.478506Z"
    },
    "papermill": {
     "duration": 0.048505,
     "end_time": "2025-01-19T09:32:55.481456",
     "exception": false,
     "start_time": "2025-01-19T09:32:55.432951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Initialize Chroma Vectorstore with OpenAI embeddings\n",
    "collection_name = \"test_index\"\n",
    "vectorstore = Chroma(collection_name=collection_name, embedding_function=embed)\n",
    "\n",
    "# Initialize a record manager to track document writes\n",
    "namespace = f\"chroma/{collection_name}\"\n",
    "record_manager = SQLRecordManager(namespace, db_url=\"sqlite:///record_manager_cache.sql\")\n",
    "record_manager.create_schema()\n",
    "\n",
    "# Define test documents\n",
    "doc1 = Document(page_content=\"kitty\", metadata={\"source\": \"kitty.txt\"})\n",
    "doc2 = Document(page_content=\"doggy\", metadata={\"source\": \"doggy.txt\"})\n",
    "doc3 = Document(page_content=\"birdie\", metadata={\"source\": \"birdie.txt\"})\n",
    "\n",
    "# Helper function to clear content (used for setup)\n",
    "def _clear():\n",
    "    index([], record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")\n",
    "\n",
    "# Clear the vector store and record manager (setup for a clean state)\n",
    "_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "137ed1d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:55.497294Z",
     "iopub.status.busy": "2025-01-19T09:32:55.496926Z",
     "iopub.status.idle": "2025-01-19T09:32:56.335445Z",
     "shell.execute_reply": "2025-01-19T09:32:56.334294Z"
    },
    "papermill": {
     "duration": 0.848391,
     "end_time": "2025-01-19T09:32:56.337347",
     "exception": false,
     "start_time": "2025-01-19T09:32:55.488956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 3, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial indexing with Full Deletion Mode to populate the vector store\n",
    "all_docs = [doc1, doc2, doc3]\n",
    "index(all_docs, record_manager, vectorstore, cleanup=\"full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1342cbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:56.353516Z",
     "iopub.status.busy": "2025-01-19T09:32:56.353194Z",
     "iopub.status.idle": "2025-01-19T09:32:57.065455Z",
     "shell.execute_reply": "2025-01-19T09:32:57.064404Z"
    },
    "papermill": {
     "duration": 0.722715,
     "end_time": "2025-01-19T09:32:57.067343",
     "exception": false,
     "start_time": "2025-01-19T09:32:56.344628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 2, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate a partial update: Only update documents related to \"kitty.txt\" and \"doggy.txt\"\n",
    "updated_doc1 = Document(page_content=\"kitty v2\", metadata={\"source\": \"kitty.txt\"})\n",
    "updated_doc2 = Document(page_content=\"doggy v2\", metadata={\"source\": \"doggy.txt\"})\n",
    "\n",
    "# Use Scoped_Full Deletion Mode to update only the specified documents\n",
    "# - The old versions of `doc1` and `doc2` are deleted.\n",
    "# - The new versions of `doc1` and `doc2` are added.\n",
    "# - `doc3` remains unchanged in the vector store.\n",
    "index([updated_doc1, updated_doc2], record_manager, vectorstore, cleanup=\"scoped_full\", source_id_key=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b3acb78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T09:32:57.083486Z",
     "iopub.status.busy": "2025-01-19T09:32:57.083146Z",
     "iopub.status.idle": "2025-01-19T09:32:57.438286Z",
     "shell.execute_reply": "2025-01-19T09:32:57.437182Z"
    },
    "papermill": {
     "duration": 0.365204,
     "end_time": "2025-01-19T09:32:57.440049",
     "exception": false,
     "start_time": "2025-01-19T09:32:57.074845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitty v2\n",
      "doggy v2\n",
      "birdie\n"
     ]
    }
   ],
   "source": [
    "# Verify the updated vector store\n",
    "results = vectorstore.similarity_search(\"kitty\", k=5)\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca66767f",
   "metadata": {
    "papermill": {
     "duration": 0.006909,
     "end_time": "2025-01-19T09:32:57.454395",
     "exception": false,
     "start_time": "2025-01-19T09:32:57.447486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Conclusion**\n",
    "\n",
    "The **LangChain Indexing API** is a versatile and efficient solution for managing documents in vector stores. By automating tasks like de-duplication, avoiding unnecessary re-computations, and handling document deletions, it significantly reduces the complexity and cost of maintaining up-to-date vector stores. The availability of multiple **deletion modes** ensures that you can tailor the indexing process to your specific needs, whether you require manual control, continuous updates, or a complete dataset refresh.\n",
    "\n",
    "When choosing a deletion mode, consider the following:\n",
    "- Use **None Deletion Mode** when you want full control over deletions and no automatic cleanup.\n",
    "- Use **Incremental Deletion Mode** for frequent updates with minimal overlap between old and new versions.\n",
    "- Use **Full Deletion Mode** for complete dataset refreshes or handling deletions of source documents.\n",
    "- Use **Scoped_Full Deletion Mode** for partial dataset refreshes with parallel processing.\n",
    "\n",
    "By understanding the strengths and use cases of each mode, you can optimize your indexing workflow and ensure that your vector store remains accurate, efficient, and up-to-date. The LangChain Indexing API, combined with its compatibility with a wide range of vector stores, makes it an essential tool for any application involving document indexing and retrieval."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 85.861571,
   "end_time": "2025-01-19T09:32:58.584075",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-19T09:31:32.722504",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
