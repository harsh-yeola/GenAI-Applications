{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdee4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking Strategies - Basic to Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU chromadb langchain llama-index langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community import embeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "local_llm = ChatOllama(model=\"mistral\")\n",
    "\n",
    "# RAG\n",
    "def rag(chunks, collection_name):\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings.ollama.OllamaEmbeddings(model='nomic-embed-text'),\n",
    "    )\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    prompt_template = \"\"\"Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | local_llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    result = chain.invoke(\"What is the use of Text Splitting?\")\n",
    "    print(result)\n",
    "\n",
    "\n",
    "# 1. Character Text Splitting\n",
    "print(\"#### Character Text Splitting ####\")\n",
    "\n",
    "text = \"Text splitting in LangChain is a critical feature that facilitates the division of large texts into smaller, manageable segments. \"\n",
    "\n",
    "# Manual Splitting\n",
    "chunks = []\n",
    "chunk_size = 35 # Characters\n",
    "for i in range(0, len(text), chunk_size):\n",
    "    chunk = text[i:i + chunk_size]\n",
    "    chunks.append(chunk)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "print(documents)\n",
    "\n",
    "# Automatic Text Splitting\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size = 35, chunk_overlap=0, separator='', strip_whitespace=False)\n",
    "documents = text_splitter.create_documents([text])\n",
    "print(documents)\n",
    "\n",
    "# 2. Recursive Character Text Splitting\n",
    "print(\"#### Recursive Character Text Splitting ####\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "with open('content.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 65, chunk_overlap=0) # [\"\\n\\n\", \"\\n\", \" \", \"\"] 65,450\n",
    "print(text_splitter.create_documents([text])) \n",
    "\n",
    "# 3. Document Specific Splitting\n",
    "print(\"#### Document Specific Splitting ####\")\n",
    "\n",
    "# Document Specific Splitting - Markdown\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "splitter = MarkdownTextSplitter(chunk_size = 40, chunk_overlap=0)\n",
    "markdown_text = \"\"\"\n",
    "# Fun in California\n",
    "\n",
    "## Driving\n",
    "\n",
    "Try driving on the 1 down to San Diego\n",
    "\n",
    "### Food\n",
    "\n",
    "Make sure to eat a burrito while you're there\n",
    "\n",
    "## Hiking\n",
    "\n",
    "Go to Yosemite\n",
    "\"\"\"\n",
    "print(splitter.create_documents([markdown_text]))\n",
    "\n",
    "# Document Specific Splitting - Python\n",
    "from langchain.text_splitter import PythonCodeTextSplitter\n",
    "python_text = \"\"\"\n",
    "class Person:\n",
    "  def __init__(self, name, age):\n",
    "    self.name = name\n",
    "    self.age = age\n",
    "\n",
    "p1 = Person(\"John\", 36)\n",
    "\n",
    "for i in range(10):\n",
    "    print (i)\n",
    "\"\"\"\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "print(python_splitter.create_documents([python_text]))\n",
    "\n",
    "# Document Specific Splitting - Javascript\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "javascript_text = \"\"\"\n",
    "// Function is called, the return value will end up in x\n",
    "let x = myFunction(4, 3);\n",
    "\n",
    "function myFunction(a, b) {\n",
    "// Function returns the product of a and b\n",
    "  return a * b;\n",
    "}\n",
    "\"\"\"\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=65, chunk_overlap=0\n",
    ")\n",
    "print(js_splitter.create_documents([javascript_text]))\n",
    "\n",
    "# 4. Semantic Chunking\n",
    "print(\"#### Semantic Chunking ####\")\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Percentile - all differences between sentences are calculated, and then any difference greater than the X percentile is split\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "text_splitter = SemanticChunker(\n",
    "    OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\" # \"standard_deviation\", \"interquartile\"\n",
    ")\n",
    "documents = text_splitter.create_documents([text])\n",
    "print(documents)\n",
    "\n",
    "# 5. Agentic Chunking\n",
    "print(\"#### Proposition-Based Chunking ####\")\n",
    "\n",
    "# https://arxiv.org/pdf/2312.06648.pdf\n",
    "\n",
    "from langchain.output_parsers.openai_tools import JsonOutputToolsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.chains import create_extraction_chain\n",
    "from typing import Optional, List\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain import hub\n",
    "\n",
    "obj = hub.pull(\"wfh/proposal-indexing\")\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "runnable = obj | llm\n",
    "\n",
    "class Sentences(BaseModel):\n",
    "    sentences: List[str]\n",
    "    \n",
    "# Extraction\n",
    "extraction_chain = create_extraction_chain_pydantic(pydantic_schema=Sentences, llm=llm)\n",
    "def get_propositions(text):\n",
    "    runnable_output = runnable.invoke({\n",
    "    \t\"input\": text\n",
    "    }).content\n",
    "    propositions = extraction_chain.invoke(runnable_output)[\"text\"][0].sentences\n",
    "    return propositions\n",
    "    \n",
    "paragraphs = text.split(\"\\n\\n\")\n",
    "text_propositions = []\n",
    "for i, para in enumerate(paragraphs[:5]):\n",
    "    propositions = get_propositions(para)\n",
    "    text_propositions.extend(propositions)\n",
    "    print (f\"Done with {i}\")\n",
    "\n",
    "print (f\"You have {len(text_propositions)} propositions\")\n",
    "print(text_propositions[:10])\n",
    "\n",
    "print(\"#### Agentic Chunking ####\")\n",
    "\n",
    "from agentic_chunker import AgenticChunker\n",
    "ac = AgenticChunker()\n",
    "ac.add_propositions(text_propositions)\n",
    "print(ac.pretty_print_chunks())\n",
    "chunks = ac.get_chunks(get_type='list_of_strings')\n",
    "print(chunks)\n",
    "documents = [Document(page_content=chunk, metadata={\"source\": \"local\"}) for chunk in chunks]\n",
    "rag(documents, \"agentic-chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Agentic Chunking\n",
    "# agentic_chunker.py\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from typing import Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from dotenv import load_dotenv\n",
    "from rich import print\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class AgenticChunker:\n",
    "    def __init__(self, openai_api_key=None):\n",
    "        self.chunks = {}\n",
    "        self.id_truncate_limit = 5\n",
    "\n",
    "        # Whether or not to update/refine summaries and titles as you get new information\n",
    "        self.generate_new_metadata_ind = True\n",
    "        self.print_logging = True\n",
    "\n",
    "        if openai_api_key is None:\n",
    "            openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "        if openai_api_key is None:\n",
    "            raise ValueError(\"API key is not provided and not found in environment variables\")\n",
    "\n",
    "        self.llm = ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=openai_api_key, temperature=0)\n",
    "\n",
    "    def add_propositions(self, propositions):\n",
    "        for proposition in propositions:\n",
    "            self.add_proposition(proposition)\n",
    "    \n",
    "    def add_proposition(self, proposition):\n",
    "        if self.print_logging:\n",
    "            print (f\"\\nAdding: '{proposition}'\")\n",
    "\n",
    "        # If it's your first chunk, just make a new chunk and don't check for others\n",
    "        if len(self.chunks) == 0:\n",
    "            if self.print_logging:\n",
    "                print (\"No chunks, creating a new one\")\n",
    "            self._create_new_chunk(proposition)\n",
    "            return\n",
    "\n",
    "        chunk_id = self._find_relevant_chunk(proposition)\n",
    "\n",
    "        # If a chunk was found then add the proposition to it\n",
    "        if chunk_id:\n",
    "            if self.print_logging:\n",
    "                print (f\"Chunk Found ({self.chunks[chunk_id]['chunk_id']}), adding to: {self.chunks[chunk_id]['title']}\")\n",
    "            self.add_proposition_to_chunk(chunk_id, proposition)\n",
    "            return\n",
    "        else:\n",
    "            if self.print_logging:\n",
    "                print (\"No chunks found\")\n",
    "            # If a chunk wasn't found, then create a new one\n",
    "            self._create_new_chunk(proposition)\n",
    "        \n",
    "\n",
    "    def add_proposition_to_chunk(self, chunk_id, proposition):\n",
    "        # Add then\n",
    "        self.chunks[chunk_id]['propositions'].append(proposition)\n",
    "\n",
    "        # Then grab a new summary\n",
    "        if self.generate_new_metadata_ind:\n",
    "            self.chunks[chunk_id]['summary'] = self._update_chunk_summary(self.chunks[chunk_id])\n",
    "            self.chunks[chunk_id]['title'] = self._update_chunk_title(self.chunks[chunk_id])\n",
    "\n",
    "    def _update_chunk_summary(self, chunk):\n",
    "        \"\"\"\n",
    "        If you add a new proposition to a chunk, you may want to update the summary or else they could get stale\n",
    "        \"\"\"\n",
    "        PROMPT = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic\n",
    "                    A new proposition was just added to one of your chunks, you should generate a very brief 1-sentence summary which will inform viewers what a chunk group is about.\n",
    "\n",
    "                    A good summary will say what the chunk is about, and give any clarifying instructions on what to add to the chunk.\n",
    "\n",
    "                    You will be given a group of propositions which are in the chunk and the chunks current summary.\n",
    "\n",
    "                    Your summaries should anticipate generalization. If you get a proposition about apples, generalize it to food.\n",
    "                    Or month, generalize it to \"date and times\".\n",
    "\n",
    "                    Example:\n",
    "                    Input: Proposition: Greg likes to eat pizza\n",
    "                    Output: This chunk contains information about the types of food Greg likes to eat.\n",
    "\n",
    "                    Only respond with the chunk new summary, nothing else.\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"user\", \"Chunk's propositions:\\n{proposition}\\n\\nCurrent chunk summary:\\n{current_summary}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        runnable = PROMPT | self.llm\n",
    "\n",
    "        new_chunk_summary = runnable.invoke({\n",
    "            \"proposition\": \"\\n\".join(chunk['propositions']),\n",
    "            \"current_summary\" : chunk['summary']\n",
    "        }).content\n",
    "\n",
    "        return new_chunk_summary\n",
    "    \n",
    "    def _update_chunk_title(self, chunk):\n",
    "        \"\"\"\n",
    "        If you add a new proposition to a chunk, you may want to update the title or else it can get stale\n",
    "        \"\"\"\n",
    "        PROMPT = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic\n",
    "                    A new proposition was just added to one of your chunks, you should generate a very brief updated chunk title which will inform viewers what a chunk group is about.\n",
    "\n",
    "                    A good title will say what the chunk is about.\n",
    "\n",
    "                    You will be given a group of propositions which are in the chunk, chunk summary and the chunk title.\n",
    "\n",
    "                    Your title should anticipate generalization. If you get a proposition about apples, generalize it to food.\n",
    "                    Or month, generalize it to \"date and times\".\n",
    "\n",
    "                    Example:\n",
    "                    Input: Summary: This chunk is about dates and times that the author talks about\n",
    "                    Output: Date & Times\n",
    "\n",
    "                    Only respond with the new chunk title, nothing else.\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"user\", \"Chunk's propositions:\\n{proposition}\\n\\nChunk summary:\\n{current_summary}\\n\\nCurrent chunk title:\\n{current_title}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        runnable = PROMPT | self.llm\n",
    "\n",
    "        updated_chunk_title = runnable.invoke({\n",
    "            \"proposition\": \"\\n\".join(chunk['propositions']),\n",
    "            \"current_summary\" : chunk['summary'],\n",
    "            \"current_title\" : chunk['title']\n",
    "        }).content\n",
    "\n",
    "        return updated_chunk_title\n",
    "\n",
    "    def _get_new_chunk_summary(self, proposition):\n",
    "        PROMPT = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic\n",
    "                    You should generate a very brief 1-sentence summary which will inform viewers what a chunk group is about.\n",
    "\n",
    "                    A good summary will say what the chunk is about, and give any clarifying instructions on what to add to the chunk.\n",
    "\n",
    "                    You will be given a proposition which will go into a new chunk. This new chunk needs a summary.\n",
    "\n",
    "                    Your summaries should anticipate generalization. If you get a proposition about apples, generalize it to food.\n",
    "                    Or month, generalize it to \"date and times\".\n",
    "\n",
    "                    Example:\n",
    "                    Input: Proposition: Greg likes to eat pizza\n",
    "                    Output: This chunk contains information about the types of food Greg likes to eat.\n",
    "\n",
    "                    Only respond with the new chunk summary, nothing else.\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"user\", \"Determine the summary of the new chunk that this proposition will go into:\\n{proposition}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        runnable = PROMPT | self.llm\n",
    "\n",
    "        new_chunk_summary = runnable.invoke({\n",
    "            \"proposition\": proposition\n",
    "        }).content\n",
    "\n",
    "        return new_chunk_summary\n",
    "    \n",
    "    def _get_new_chunk_title(self, summary):\n",
    "        PROMPT = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    You are the steward of a group of chunks which represent groups of sentences that talk about a similar topic\n",
    "                    You should generate a very brief few word chunk title which will inform viewers what a chunk group is about.\n",
    "\n",
    "                    A good chunk title is brief but encompasses what the chunk is about\n",
    "\n",
    "                    You will be given a summary of a chunk which needs a title\n",
    "\n",
    "                    Your titles should anticipate generalization. If you get a proposition about apples, generalize it to food.\n",
    "                    Or month, generalize it to \"date and times\".\n",
    "\n",
    "                    Example:\n",
    "                    Input: Summary: This chunk is about dates and times that the author talks about\n",
    "                    Output: Date & Times\n",
    "\n",
    "                    Only respond with the new chunk title, nothing else.\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"user\", \"Determine the title of the chunk that this summary belongs to:\\n{summary}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        runnable = PROMPT | self.llm\n",
    "\n",
    "        new_chunk_title = runnable.invoke({\n",
    "            \"summary\": summary\n",
    "        }).content\n",
    "\n",
    "        return new_chunk_title\n",
    "\n",
    "\n",
    "    def _create_new_chunk(self, proposition):\n",
    "        new_chunk_id = str(uuid.uuid4())[:self.id_truncate_limit] # I don't want long ids\n",
    "        new_chunk_summary = self._get_new_chunk_summary(proposition)\n",
    "        new_chunk_title = self._get_new_chunk_title(new_chunk_summary)\n",
    "\n",
    "        self.chunks[new_chunk_id] = {\n",
    "            'chunk_id' : new_chunk_id,\n",
    "            'propositions': [proposition],\n",
    "            'title' : new_chunk_title,\n",
    "            'summary': new_chunk_summary,\n",
    "            'chunk_index' : len(self.chunks)\n",
    "        }\n",
    "        if self.print_logging:\n",
    "            print (f\"Created new chunk ({new_chunk_id}): {new_chunk_title}\")\n",
    "    \n",
    "    def get_chunk_outline(self):\n",
    "        \"\"\"\n",
    "        Get a string which represents the chunks you currently have.\n",
    "        This will be empty when you first start off\n",
    "        \"\"\"\n",
    "        chunk_outline = \"\"\n",
    "\n",
    "        for chunk_id, chunk in self.chunks.items():\n",
    "            single_chunk_string = f\"\"\"Chunk ({chunk['chunk_id']}): {chunk['title']}\\nSummary: {chunk['summary']}\\n\\n\"\"\"\n",
    "        \n",
    "            chunk_outline += single_chunk_string\n",
    "        \n",
    "        return chunk_outline\n",
    "\n",
    "    def _find_relevant_chunk(self, proposition):\n",
    "        current_chunk_outline = self.get_chunk_outline()\n",
    "\n",
    "        PROMPT = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"\"\"\n",
    "                    Determine whether or not the \"Proposition\" should belong to any of the existing chunks.\n",
    "\n",
    "                    A proposition should belong to a chunk of their meaning, direction, or intention are similar.\n",
    "                    The goal is to group similar propositions and chunks.\n",
    "\n",
    "                    If you think a proposition should be joined with a chunk, return the chunk id.\n",
    "                    If you do not think an item should be joined with an existing chunk, just return \"No chunks\"\n",
    "\n",
    "                    Example:\n",
    "                    Input:\n",
    "                        - Proposition: \"Greg really likes hamburgers\"\n",
    "                        - Current Chunks:\n",
    "                            - Chunk ID: 2n4l3d\n",
    "                            - Chunk Name: Places in San Francisco\n",
    "                            - Chunk Summary: Overview of the things to do with San Francisco Places\n",
    "\n",
    "                            - Chunk ID: 93833k\n",
    "                            - Chunk Name: Food Greg likes\n",
    "                            - Chunk Summary: Lists of the food and dishes that Greg likes\n",
    "                    Output: 93833k\n",
    "                    \"\"\",\n",
    "                ),\n",
    "                (\"user\", \"Current Chunks:\\n--Start of current chunks--\\n{current_chunk_outline}\\n--End of current chunks--\"),\n",
    "                (\"user\", \"Determine if the following statement should belong to one of the chunks outlined:\\n{proposition}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        runnable = PROMPT | self.llm\n",
    "\n",
    "        chunk_found = runnable.invoke({\n",
    "            \"proposition\": proposition,\n",
    "            \"current_chunk_outline\": current_chunk_outline\n",
    "        }).content\n",
    "\n",
    "        # Pydantic data class\n",
    "        class ChunkID(BaseModel):\n",
    "            \"\"\"Extracting the chunk id\"\"\"\n",
    "            chunk_id: Optional[str]\n",
    "            \n",
    "        # Extraction to catch-all LLM responses. This is a bandaid\n",
    "        extraction_chain = create_extraction_chain_pydantic(pydantic_schema=ChunkID, llm=self.llm)\n",
    "        extraction_found = extraction_chain.invoke(chunk_found)[\"text\"]\n",
    "        if extraction_found:\n",
    "            chunk_found = extraction_found[0].chunk_id\n",
    "\n",
    "        # If you got a response that isn't the chunk id limit, chances are it's a bad response or it found nothing\n",
    "        # So return nothing\n",
    "        if len(chunk_found) != self.id_truncate_limit:\n",
    "            return None\n",
    "\n",
    "        return chunk_found\n",
    "    \n",
    "    def get_chunks(self, get_type='dict'):\n",
    "        \"\"\"\n",
    "        This function returns the chunks in the format specified by the 'get_type' parameter.\n",
    "        If 'get_type' is 'dict', it returns the chunks as a dictionary.\n",
    "        If 'get_type' is 'list_of_strings', it returns the chunks as a list of strings, where each string is a proposition in the chunk.\n",
    "        \"\"\"\n",
    "        if get_type == 'dict':\n",
    "            return self.chunks\n",
    "        if get_type == 'list_of_strings':\n",
    "            chunks = []\n",
    "            for chunk_id, chunk in self.chunks.items():\n",
    "                chunks.append(\" \".join([x for x in chunk['propositions']]))\n",
    "            return chunks\n",
    "    \n",
    "    def pretty_print_chunks(self):\n",
    "        print (f\"\\nYou have {len(self.chunks)} chunks\\n\")\n",
    "        for chunk_id, chunk in self.chunks.items():\n",
    "            print(f\"Chunk #{chunk['chunk_index']}\")\n",
    "            print(f\"Chunk ID: {chunk_id}\")\n",
    "            print(f\"Summary: {chunk['summary']}\")\n",
    "            print(f\"Propositions:\")\n",
    "            for prop in chunk['propositions']:\n",
    "                print(f\"    -{prop}\")\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "    def pretty_print_chunk_outline(self):\n",
    "        print (\"Chunk Outline\\n\")\n",
    "        print(self.get_chunk_outline())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ac = AgenticChunker()\n",
    "\n",
    "    ## Comment and uncomment the propositions to your hearts content\n",
    "    propositions = [\n",
    "        'The month is October.',\n",
    "        'The year is 2023.',\n",
    "        \"One of the most important things that I didn't understand about the world as a child was the degree to which the returns for performance are superlinear.\",\n",
    "        'Teachers and coaches implicitly told us that the returns were linear.',\n",
    "        \"I heard a thousand times that 'You get out what you put in.'\",\n",
    "        # 'Teachers and coaches meant well.',\n",
    "        # \"The statement that 'You get out what you put in' is rarely true.\",\n",
    "        # \"If your product is only half as good as your competitor's product, you do not get half as many customers.\",\n",
    "        # \"You get no customers if your product is only half as good as your competitor's product.\",\n",
    "        # 'You go out of business if you get no customers.',\n",
    "        # 'The returns for performance are superlinear in business.',\n",
    "        # 'Some people think the superlinear returns for performance are a flaw of capitalism.',\n",
    "        # 'Some people think that changing the rules of capitalism would stop the superlinear returns for performance from being true.',\n",
    "        # 'Superlinear returns for performance are a feature of the world.',\n",
    "        # 'Superlinear returns for performance are not an artifact of rules that humans have invented.',\n",
    "        # 'The same pattern of superlinear returns is observed in fame.',\n",
    "        # 'The same pattern of superlinear returns is observed in power.',\n",
    "        # 'The same pattern of superlinear returns is observed in military victories.',\n",
    "        # 'The same pattern of superlinear returns is observed in knowledge.',\n",
    "        # 'The same pattern of superlinear returns is observed in benefit to humanity.',\n",
    "        # 'In fame, power, military victories, knowledge, and benefit to humanity, the rich get richer.'\n",
    "    ]\n",
    "    \n",
    "    ac.add_propositions(propositions)\n",
    "    ac.pretty_print_chunks()\n",
    "    ac.pretty_print_chunk_outline()\n",
    "    print (ac.get_chunks(get_type='list_of_strings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # content.txt\n",
    "# Text splitting in LangChain is a critical feature that facilitates the division of large texts into smaller, manageable segments. \n",
    "# This capability is vital for improving comprehension and processing efficiency, especially in tasks that require detailed analysis or extraction of specific contexts.\n",
    "\n",
    "# ChatGPT, developed by OpenAI, represents a leap forward in natural language processing technologies.\n",
    "# It's a conversational AI model capable of understanding and generating human-like text, allowing for dynamic interactions and providing responses that are remarkably coherent and contextually relevant. ChatGPT has been integrated into a multitude of applications, revolutionizing the way we interact with machines and access information.\n",
    "\n",
    "# By leveraging LangChain for text splitting, users can efficiently navigate and analyze vast amounts of text data, facilitating a deeper understanding and more insightful conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b4b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output\n",
    "\n",
    "# #### Character Text Splitting ####\n",
    "# [\n",
    "#     Document(page_content='Text splitting in LangChain is a cr', metadata={'source': 'local'}),\n",
    "#     Document(page_content='itical feature that facilitates the', metadata={'source': 'local'}),\n",
    "#     Document(page_content=' division of large texts into small', metadata={'source': 'local'}),\n",
    "#     Document(page_content='er, manageable segments. ', metadata={'source': 'local'})\n",
    "# ]\n",
    "# [\n",
    "#     Document(page_content='Text splitting in LangChain is a cr'),\n",
    "#     Document(page_content='itical feature that facilitates the'),\n",
    "#     Document(page_content=' division of large texts into small'),\n",
    "#     Document(page_content='er, manageable segments. ')\n",
    "# ]\n",
    "# #### Recursive Character Text Splitting ####\n",
    "# [\n",
    "#     Document(page_content='Text splitting in LangChain is a critical feature that'),\n",
    "#     Document(page_content='facilitates the division of large texts into smaller, manageable'),\n",
    "#     Document(page_content='segments.'),\n",
    "#     Document(page_content='This capability is vital for improving comprehension and'),\n",
    "#     Document(page_content='processing efficiency, especially in tasks that require detailed'),\n",
    "#     Document(page_content='analysis or extraction of specific contexts.'),\n",
    "#     Document(page_content='ChatGPT, developed by OpenAI, represents a leap forward in'),\n",
    "#     Document(page_content='natural language processing technologies.'),\n",
    "#     Document(page_content=\"It's a conversational AI model capable of understanding and\"),\n",
    "#     Document(page_content='generating human-like text, allowing for dynamic interactions'),\n",
    "#     Document(page_content='and providing responses that are remarkably coherent and'),\n",
    "#     Document(page_content='contextually relevant. ChatGPT has been integrated into a'),\n",
    "#     Document(page_content='multitude of applications, revolutionizing the way we interact'),\n",
    "#     Document(page_content='with machines and access information.'),\n",
    "#     Document(page_content='By leveraging LangChain for text splitting, users can'),\n",
    "#     Document(page_content='efficiently navigate and analyze vast amounts of text data,'),\n",
    "#     Document(page_content='facilitating a deeper understanding and more insightful'),\n",
    "#     Document(page_content='conclusions.')\n",
    "# ]\n",
    "# #### Document Specific Splitting ####\n",
    "# [\n",
    "#     Document(page_content='# Fun in California\\n\\n## Driving'),\n",
    "#     Document(page_content='Try driving on the 1 down to San Diego'),\n",
    "#     Document(page_content='### Food'),\n",
    "#     Document(page_content=\"Make sure to eat a burrito while you're\"),\n",
    "#     Document(page_content='there'),\n",
    "#     Document(page_content='## Hiking\\n\\nGo to Yosemite')\n",
    "# ]\n",
    "# [\n",
    "#     Document(page_content='class Person:\\n  def __init__(self, name, age):\\n    self.name = name\\n    self.age = age'),\n",
    "#     Document(page_content='p1 = Person(\"John\", 36)\\n\\nfor i in range(10):\\n    print (i)')\n",
    "# ]\n",
    "# [\n",
    "#     Document(page_content='// Function is called, the return value will end up in x'),\n",
    "#     Document(page_content='let x = myFunction(4, 3);'),\n",
    "#     Document(page_content='function myFunction(a, b) {'),\n",
    "#     Document(page_content='// Function returns the product of a and b\\n  return a * b;\\n}')\n",
    "# ]\n",
    "# #### Semantic Chunking ####\n",
    "# [\n",
    "#     Document(\n",
    "#         page_content='Text splitting in LangChain is a critical feature that facilitates the division of large texts into \n",
    "# smaller, manageable segments. This capability is vital for improving comprehension and processing efficiency, especially in tasks\n",
    "# that require detailed analysis or extraction of specific contexts.'\n",
    "#     ),\n",
    "#     Document(\n",
    "#         page_content=\"ChatGPT, developed by OpenAI, represents a leap forward in natural language processing technologies. It's a\n",
    "# conversational AI model capable of understanding and generating human-like text, allowing for dynamic interactions and providing \n",
    "# responses that are remarkably coherent and contextually relevant. ChatGPT has been integrated into a multitude of applications, \n",
    "# revolutionizing the way we interact with machines and access information. By leveraging LangChain for text splitting, users can \n",
    "# efficiently navigate and analyze vast amounts of text data, facilitating a deeper understanding and more insightful conclusions.\"\n",
    "#     )\n",
    "# ]\n",
    "# #### Proposition-Based Chunking ####\n",
    "# Done with 0\n",
    "# Done with 1\n",
    "# Done with 2\n",
    "# You have 17 propositions\n",
    "# [\n",
    "#     'Text splitting in LangChain is a critical feature.',\n",
    "#     'Text splitting facilitates the division of large texts into smaller, manageable segments.',\n",
    "#     'This capability is vital for improving comprehension and processing efficiency.',\n",
    "#     'It is especially important in tasks that require detailed analysis or extraction of specific contexts.',\n",
    "#     'ChatGPT was developed by OpenAI.',\n",
    "#     'OpenAI developed ChatGPT.',\n",
    "#     'ChatGPT represents a leap forward in natural language processing technologies.',\n",
    "#     'ChatGPT is a conversational AI model.',\n",
    "#     'ChatGPT is capable of understanding and generating human-like text.',\n",
    "#     'ChatGPT allows for dynamic interactions.'\n",
    "# ]\n",
    "# #### Agentic Chunking ####\n",
    "\n",
    "# Adding: 'Text splitting in LangChain is a critical feature.'\n",
    "# No chunks, creating a new one\n",
    "# Created new chunk (0e05f): LangChain Features\n",
    "\n",
    "# Adding: 'Text splitting facilitates the division of large texts into smaller, manageable segments.'\n",
    "# No chunks found\n",
    "# Created new chunk (471d6): Text Segmentation Techniques\n",
    "\n",
    "# Adding: 'This capability is vital for improving comprehension and processing efficiency.'\n",
    "# No chunks found\n",
    "# Created new chunk (9ba91): Capabilities Importance & Benefits\n",
    "\n",
    "# Adding: 'It is especially important in tasks that require detailed analysis or extraction of specific contexts.'\n",
    "# No chunks found\n",
    "# Created new chunk (3af8b): Analytical Processes\n",
    "\n",
    "# Adding: 'ChatGPT was developed by OpenAI.'\n",
    "# No chunks found\n",
    "# Created new chunk (e2947): ChatGPT Development & Features\n",
    "\n",
    "# Adding: 'OpenAI developed ChatGPT.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT Development & Features\n",
    "\n",
    "# Adding: 'ChatGPT represents a leap forward in natural language processing technologies.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT Development\n",
    "\n",
    "# Adding: 'ChatGPT is a conversational AI model.'\n",
    "# Chunk Found (e2947), adding to: Advancements in Natural Language Processing\n",
    "\n",
    "# Adding: 'ChatGPT is capable of understanding and generating human-like text.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Development and Capabilities\n",
    "\n",
    "# Adding: 'ChatGPT allows for dynamic interactions.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities, and Significance\n",
    "\n",
    "# Adding: 'ChatGPT provides responses that are remarkably coherent and contextually relevant.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Overview and Innovations\n",
    "\n",
    "# Adding: 'ChatGPT has been integrated into a multitude of applications.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities & Impact\n",
    "\n",
    "# Adding: 'ChatGPT revolutionized the way we interact with machines.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Overview & Applications\n",
    "\n",
    "# Adding: 'ChatGPT revolutionized the way we access information.'\n",
    "# Chunk Found (e2947), adding to: ChatGPT: Development, Capabilities & Impact\n",
    "\n",
    "# Adding: 'Users can leverage LangChain for text splitting.'\n",
    "# Chunk Found (0e05f), adding to: LangChain Features\n",
    "\n",
    "# Adding: 'LangChain allows users to efficiently navigate and analyze vast amounts of text data.'\n",
    "# Chunk Found (0e05f), adding to: Using LangChain for Text Splitting\n",
    "\n",
    "# Adding: 'Text splitting with LangChain facilitates a deeper understanding and more insightful conclusions.'\n",
    "# Chunk Found (0e05f), adding to: LangChain Text Splitting and Analysis\n",
    "\n",
    "# You have 5 chunks\n",
    "\n",
    "# Chunk #0\n",
    "# Chunk ID: 0e05f\n",
    "# Summary: This chunk contains information about using LangChain for text splitting, including its advantages for navigating, \n",
    "# analyzing, and understanding large text datasets.\n",
    "# Propositions:\n",
    "#     -Text splitting in LangChain is a critical feature.\n",
    "#     -Users can leverage LangChain for text splitting.\n",
    "#     -LangChain allows users to efficiently navigate and analyze vast amounts of text data.\n",
    "#     -Text splitting with LangChain facilitates a deeper understanding and more insightful conclusions.\n",
    "\n",
    "\n",
    "\n",
    "# Chunk #1\n",
    "# Chunk ID: 471d6\n",
    "# Summary: This chunk contains information about techniques and methods for dividing texts into smaller segments.\n",
    "# Propositions:\n",
    "#     -Text splitting facilitates the division of large texts into smaller, manageable segments.\n",
    "\n",
    "\n",
    "\n",
    "# Chunk #2\n",
    "# Chunk ID: 9ba91\n",
    "# Summary: This chunk contains information about the importance and benefits of certain capabilities.\n",
    "# Propositions:\n",
    "#     -This capability is vital for improving comprehension and processing efficiency.\n",
    "\n",
    "\n",
    "\n",
    "# Chunk #3\n",
    "# Chunk ID: 3af8b\n",
    "# Summary: This chunk contains information about the importance of certain processes in tasks requiring detailed analysis or \n",
    "# context extraction.\n",
    "# Propositions:\n",
    "#     -It is especially important in tasks that require detailed analysis or extraction of specific contexts.\n",
    "\n",
    "\n",
    "\n",
    "# Chunk #4\n",
    "# Chunk ID: e2947\n",
    "# Summary: This chunk contains information about the development, capabilities, significance, functionalities, and applications of \n",
    "# ChatGPT, a conversational AI model by OpenAI.\n",
    "# Propositions:\n",
    "#     -ChatGPT was developed by OpenAI.\n",
    "#     -OpenAI developed ChatGPT.\n",
    "#     -ChatGPT represents a leap forward in natural language processing technologies.\n",
    "#     -ChatGPT is a conversational AI model.\n",
    "#     -ChatGPT is capable of understanding and generating human-like text.\n",
    "#     -ChatGPT allows for dynamic interactions.\n",
    "#     -ChatGPT provides responses that are remarkably coherent and contextually relevant.\n",
    "#     -ChatGPT has been integrated into a multitude of applications.\n",
    "#     -ChatGPT revolutionized the way we interact with machines.\n",
    "#     -ChatGPT revolutionized the way we access information.\n",
    "\n",
    "\n",
    "\n",
    "# None\n",
    "# [\n",
    "#     'Text splitting in LangChain is a critical feature. Users can leverage LangChain for text splitting. LangChain allows users \n",
    "# to efficiently navigate and analyze vast amounts of text data. Text splitting with LangChain facilitates a deeper understanding \n",
    "# and more insightful conclusions.',\n",
    "#     'Text splitting facilitates the division of large texts into smaller, manageable segments.',\n",
    "#     'This capability is vital for improving comprehension and processing efficiency.',\n",
    "#     'It is especially important in tasks that require detailed analysis or extraction of specific contexts.',\n",
    "#     'ChatGPT was developed by OpenAI. OpenAI developed ChatGPT. ChatGPT represents a leap forward in natural language processing \n",
    "# technologies. ChatGPT is a conversational AI model. ChatGPT is capable of understanding and generating human-like text. ChatGPT \n",
    "# allows for dynamic interactions. ChatGPT provides responses that are remarkably coherent and contextually relevant. ChatGPT has \n",
    "# been integrated into a multitude of applications. ChatGPT revolutionized the way we interact with machines. ChatGPT \n",
    "# revolutionized the way we access information.'\n",
    "# ]\n",
    "#  Text splitting is a feature used to divide large texts into smaller, manageable segments. This facilitates improved \n",
    "# comprehension and processing efficiency, making it especially important in tasks that require detailed analysis or extraction of \n",
    "# specific contexts. It enables users to more efficiently navigate and analyze vast amounts of text data, leading to deeper \n",
    "# understanding and more insightful conclusions.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
